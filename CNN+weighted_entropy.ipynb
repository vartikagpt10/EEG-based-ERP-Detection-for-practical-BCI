{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN+weighted_entropy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vartikagpt10/EEG-based-ERP-Detection-for-practical-BCI/blob/main/CNN%2Bweighted_entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbT268a2eqzL"
      },
      "source": [
        "# Download and Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pt_de-II0NC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141298db-13d6-42a8-9e40-581a7755c710"
      },
      "source": [
        "!pip install --upgrade gdown pyriemann\n",
        "!gdown https://drive.google.com/uc?id=1RCZlEI1P0NpCqNkjlQMPnTAOU2phFJkq -O /tmp/Data.zip\n",
        "\n",
        "import zipfile\n",
        "local_zip = '//tmp/Data.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp/Data')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gdown\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyriemann\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/5e/1df5684d9f43b574d7e2807869578750da94286508ab2129d62c26c1eef0/pyriemann-0.2.6-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from gdown) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyriemann) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from pyriemann) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from pyriemann) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from pyriemann) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyriemann) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pyriemann) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pyriemann) (2018.9)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp36-none-any.whl size=9694 sha256=b58eeb203971d76b2a3f21d0de965d6cad876b1679e5655992d43f1dd61cdf2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown, pyriemann\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed gdown-3.12.2 pyriemann-0.2.6\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RCZlEI1P0NpCqNkjlQMPnTAOU2phFJkq\n",
            "To: /tmp/Data.zip\n",
            "226MB [00:01, 203MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOOi1mRFOBs9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "from scipy.signal import filtfilt, cheby2\n",
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkTA6-eNNqgh"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QN3hXKNoh5Y"
      },
      "source": [
        "train_folder_path = '/tmp/Data/Training set/'\n",
        "validation_folder_path = '/tmp/Data/Validation set/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir_rf2xIemy2"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzUZV2RWQmcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88691ebe-1e3b-4aca-bfac-dc877cba69ed"
      },
      "source": [
        "c=0\n",
        "for i in os.listdir(train_folder_path):\n",
        "  c+=1\n",
        "  if c==1:\n",
        "    temp=sio.loadmat(train_folder_path+i)\n",
        "    dat=np.squeeze(temp['epo_tr']['x']).tolist()\n",
        "    dat=np.array(dat)\n",
        "    lab=np.squeeze(temp['epo_tr']['y']).tolist()\n",
        "    lab=np.array(lab)[0,:]\n",
        "    training_data=dat\n",
        "    training_labels=lab\n",
        "    continue\n",
        "  temp=sio.loadmat(train_folder_path+i)\n",
        "  dat=np.squeeze(temp['epo_tr']['x']).tolist()\n",
        "  dat=np.array(dat)\n",
        "  lab=np.squeeze(temp['epo_tr']['y']).tolist()\n",
        "  lab=np.array(lab)[0,:]\n",
        "  training_data=np.concatenate((training_data,dat),axis=2)\n",
        "  training_labels=np.concatenate((training_labels,lab))\n",
        "training_data=training_data.reshape((2700,56,100))\n",
        "training_data=training_data[:,:32,:]\n",
        "print(\"Training data shape:\",training_data.shape)\n",
        "print(\"Training labels shape:\",training_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape: (2700, 32, 100)\n",
            "Training labels shape: (2700,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KILTNPQNm8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4a73c1-3b37-4bbc-e338-49b901e4fd15"
      },
      "source": [
        "c=0\n",
        "for i in os.listdir(validation_folder_path):\n",
        "  c+=1\n",
        "  if c==1:\n",
        "    temp=sio.loadmat(validation_folder_path+i)\n",
        "    dat=np.squeeze(temp['epo_val']['x']).tolist()\n",
        "    dat=np.array(dat)\n",
        "    lab=np.squeeze(temp['epo_val']['y']).tolist()\n",
        "    lab=np.array(lab)[0,:]\n",
        "    validation_data=dat\n",
        "    validation_labels=lab\n",
        "    continue\n",
        "  temp=sio.loadmat(validation_folder_path+i)\n",
        "  dat=np.squeeze(temp['epo_val']['x']).tolist()\n",
        "  dat=np.array(dat)\n",
        "  lab=np.squeeze(temp['epo_val']['y']).tolist()\n",
        "  lab=np.array(lab)[0,:]\n",
        "  validation_data=np.concatenate((validation_data,dat),axis=2)\n",
        "  validation_labels=np.concatenate((validation_labels,lab))\n",
        "validation_data=validation_data.reshape((900,56,100))\n",
        "validation_data=validation_data[:,:32,:]\n",
        "print(\"Validation data shape:\",validation_data.shape)\n",
        "print(\"Validation labels shape:\",validation_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation data shape: (900, 32, 100)\n",
            "Validation labels shape: (900,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIPSLhEeLV0X"
      },
      "source": [
        "# dat=np.squeeze(temp['epo_val']['y']).tolist()\n",
        "# dat=np.array(dat)[0,:]\n",
        "# dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEPY4yx-eh95"
      },
      "source": [
        "# Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWaU1-3gWQxh"
      },
      "source": [
        "def chebyBandpass(signal, lowcut, fs, order):\n",
        "  nyq=0.5*fs\n",
        "  low = lowcut/nyq\n",
        "  # high = highcut / nyq\n",
        "  b, a = cheby2(order,12, low, btype='low')\n",
        "  filtered = filtfilt(b, a, signal)\n",
        "  return filtered\n",
        "\n",
        "def filterall(data):\n",
        "  filtered=[]\n",
        "  for trial in data:\n",
        "    temp_filtered=[]\n",
        "    for channel in trial:\n",
        "      temp_filtered.append(chebyBandpass(channel,20,100,3))\n",
        "    filtered.append(temp_filtered)\n",
        "  return np.array(filtered)\n",
        "\n",
        "filt_train=filterall(training_data)\n",
        "filt_val=filterall(validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyBKfO8ge2P8"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zP6xr49G_EO"
      },
      "source": [
        "##CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk2xcfEQ12Ms"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization, Activation, AveragePooling2D, Dropout, SeparableConv2D, Flatten, Dense, MaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SihwjJv620cA"
      },
      "source": [
        "###EEGNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odBdMFFAwjoL"
      },
      "source": [
        "def get_model(flt_size=32, drop=0.25):\n",
        "  #build model\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(Conv2D(64, (2, flt_size), padding=\"same\", input_shape=(32,100,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  C = 32\n",
        "  model.add(DepthwiseConv2D((C, 1), padding=\"valid\", depth_multiplier=2))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(AveragePooling2D(pool_size=(1, 4), padding=\"valid\"))\n",
        "  model.add(Dropout(drop))\n",
        "  model.add(SeparableConv2D(16, (1, 16), padding=\"same\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(AveragePooling2D(pool_size=(1, 8), padding=\"valid\"))\n",
        "  model.add(Dropout(drop))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVev8fuF2g-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a03d426-d238-4a37-b299-2b65f3cdceca"
      },
      "source": [
        "filt_train = filt_train[:180,:,:]\n",
        "training_labels = training_labels[:180]\n",
        "filt_val = filt_val[:180,:,:]\n",
        "validation_labels = validation_labels[:180]\n",
        "training_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KLVk22S0Jrt"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Calculate the weights for each class so that we can balance the data\n",
        "weights = class_weight.compute_class_weight('balanced',\n",
        "                                            np.unique(training_labels),\n",
        "                                            training_labels)\n",
        "\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YbQLt0Sp4ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6d7481-2c85-4d95-c525-55f2ad02ee7d"
      },
      "source": [
        "weights = {0: weights[0], 1: weights[1]}\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5960264900662252, 1: 3.103448275862069}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR8-xkJHu54o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3dfd114-2ae3-4ae6-f71e-a2eada07cfef"
      },
      "source": [
        "filt_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180, 32, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOanuqbz2Qfo"
      },
      "source": [
        "filt_train = filt_train[..., np.newaxis]\n",
        "training_labels = training_labels[...,np.newaxis]\n",
        "filt_val = filt_val[..., np.newaxis]\n",
        "validation_labels = validation_labels[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNjDfLPp0Mxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee79f29e-2ca4-423c-d212-b8e2c49078c7"
      },
      "source": [
        "model_new = get_model()\n",
        "opt = optimizers.Adam(learning_rate=0.02)\n",
        "model_new.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model_new.fit(filt_train, training_labels, epochs=200, class_weight=weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8233 - accuracy: 0.4500\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6818 - accuracy: 0.6167\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.5056\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.3889\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6462 - accuracy: 0.6056\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.6833\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6432 - accuracy: 0.6833\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6833\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.4722\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.5389\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6305 - accuracy: 0.6556\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6722\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.7056\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6324 - accuracy: 0.6833\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6404 - accuracy: 0.6833\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.7111\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7264 - accuracy: 0.6944\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.7333\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.7111\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.6833\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.8000\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6201 - accuracy: 0.8056\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.7278\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6585 - accuracy: 0.6944\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6420 - accuracy: 0.7389\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6496 - accuracy: 0.8000\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6279 - accuracy: 0.8000\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.8056\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6168 - accuracy: 0.7944\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.7333\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6179 - accuracy: 0.7944\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6177 - accuracy: 0.8056\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6227 - accuracy: 0.7833\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.8000\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.7889\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.8111\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.7778\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.7833\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.8167\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6261 - accuracy: 0.8056\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.8167\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.8222\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6148 - accuracy: 0.8056\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.7444\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.8222\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.8111\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.8111\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.7889\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.8056\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.8056\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.7944\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6221 - accuracy: 0.7778\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.7889\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6287 - accuracy: 0.7944\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6211 - accuracy: 0.8111\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.7556\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.7611\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.7056\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.7833\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7833\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.7833\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7167\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7889\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7944\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.8056\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.8222\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6247 - accuracy: 0.8167\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.7889\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.8000\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.7889\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.7833\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.7722\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.7778\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.7167\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.7167\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6232 - accuracy: 0.7944\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.7944\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.7556\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.8111\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.8111\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.8167\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.8278\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7944\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7889\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.7778\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.7833\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.7611\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.7167\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.7944\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.7944\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6279 - accuracy: 0.8000\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.7889\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6146 - accuracy: 0.7833\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6312 - accuracy: 0.7889\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6222 - accuracy: 0.7944\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.7833\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.7722\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.6944\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6229 - accuracy: 0.8111\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6411 - accuracy: 0.6444\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.6500\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.6611\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.7333\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.7889\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.7833\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7889\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.8111\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.8056\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.7444\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.8000\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.7722\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.8278\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.8111\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.8000\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6473 - accuracy: 0.8000\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6413 - accuracy: 0.7944\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.7833\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.7889\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6286 - accuracy: 0.7889\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6202 - accuracy: 0.7889\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6239 - accuracy: 0.8000\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.7889\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6497 - accuracy: 0.7889\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.7944\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.8000\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.8111\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.8056\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.8056\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.8056\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 0.8056\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7944\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.8056\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6183 - accuracy: 0.8167\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6185 - accuracy: 0.8222\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6307 - accuracy: 0.6611\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.8222\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.8111\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6302 - accuracy: 0.8222\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.8167\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.7722\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.7667\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.7500\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.7278\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.7111\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.7778\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.8056\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.8222\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6315 - accuracy: 0.8222\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6147 - accuracy: 0.8222\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6133 - accuracy: 0.8222\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.8222\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.8222\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6175 - accuracy: 0.8111\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.8000\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.8167\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.7667\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.8167\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6778\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6232 - accuracy: 0.7667\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.8000\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6228 - accuracy: 0.8111\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.7611\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.8000\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.7000\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.7000\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7056\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.8111\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.8222\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.8000\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.8056\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.8000\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.7556\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6163 - accuracy: 0.8056\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6365 - accuracy: 0.8167\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.8111\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.8111\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.7722\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.8056\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.8056\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.7778\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6221 - accuracy: 0.7944\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.7000\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6134 - accuracy: 0.7444\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.7944\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6365 - accuracy: 0.8056\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.7778\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.7944\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.8056\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.7944\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.7333\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3191d0e780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEC3T0ZrOAOI"
      },
      "source": [
        "predictions = model_new.predict_proba(filt_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUaXvW3DbnZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a276bb-fa86-4812-b914-25542ccb7736"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUveXb8nb7aA"
      },
      "source": [
        "temp=scipy.io.loadmat('/content/drive/My Drive/Test set/Data_Sample01.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chdtboTZc_Ny"
      },
      "source": [
        "dat=np.squeeze(temp['epo_te']['x']).tolist()\n",
        "dat=np.array(dat)\n",
        "\n",
        "test_data=dat\n",
        "#test_data=np.concatenate((test_data,dat),axis=2)\n",
        "test_data = test_data[:, :32,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPVFCXR_rSZl"
      },
      "source": [
        "test_data = test_data.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmOnA4N6eMfq"
      },
      "source": [
        "test_data = test_data[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLWpd1nXf-xJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb573d6-cbc9-4113-aec5-a32434d2bc72"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 32, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaBWlfTFaYa6"
      },
      "source": [
        "predsubj1 = model_new.predict_proba(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2NQOTEqSnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b90b7f-e4be-45b3-a902-a17b5ea24d7b"
      },
      "source": [
        "predsubj1[:60,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666,\n",
              "       0.46799666, 0.46799666, 0.46799666, 0.46799666, 0.46799666],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqEa24dfqtgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c3c740-1569-42f4-e65f-fbb4f4002b29"
      },
      "source": [
        "predsubj1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}